############## WWWizard ##############
#
# Well, this is my code. As you can see,
# it's a bit of a mess, but I'll keep working
# on it since it's still in beta, and I plan
# to add many more features soon.
#                      
######################################
try: 
        import requests
        import re
        import argparse
        import sys
        import multiprocessing
        import concurrent.futures
        import random
        import time
        from string import Template
        from datetime import datetime
        from functools import partial

except Exception as e:
        print("\033[0m[\033[0;31mError\033[0m] {e}")


USER_AGENTS = [
    {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.90 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9",
        "Connection": "keep-alive"
    },
    {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.5",
        "Connection": "keep-alive"
    },
    {
        "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.5938.92 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.8",
        "Connection": "keep-alive"
    },
    {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.5",
        "Connection": "keep-alive"
    },
    {
        "User-Agent": "Mozilla/5.0 (Linux; Android 13; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.90 Mobile Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9",
        "Connection": "keep-alive"
    }
]
# Set here default headers
DEFAULT_HEADERS = {
        "User-Agent": "Mozilla/5.0 (Linux; Android 13; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.90 Mobile Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9",
        "Connection": "keep-alive"
    }
# Add more
CAPTCHA_PATTERNS = [
        "captcha",
        "recaptcha", 
        "g-recaptcha",
        "hcaptcha",
        "cf_captcha",
        "cloudflare challenge",
        "are you human",
        "prove you are human",
        "captcha-form",
        "challenge-form",
        "captcha-image",
        "captcha-input",
        "captcha-wrapper",
        "google recaptcha",
        "solve this puzzle",
        "robot check",
        "anti-bot",
        "anti-spam"
]
# Add more
WAF_PATTERNS = {
        "Cloudflare": [
            r"cloudflare",
            r"cf-ray",
            r"attention required",
            r"incapsula"
        ],
        "Cloudfront (AWS)": [
            r"cloudfront",
            r"aws"
        ],
        "Akamai": [
            r"akamaighost",
            r"akamai"
        ],
        "Imperva": [
            r"incapsula",
            r"imperva"
        ],
        "Sucuri": [
            r"sucuri/cloudproxy",
            r"access denied"
        ],
        "ModSecurity": [
            r"mod_security",
            r"libmodsecurity"
        ],
        "Wordfence": [
            r"wordfence",
            r"generated by wordfence"
        ],
        "Comodo": [
            r"protected by comodo",
            r"comodo waf"
        ]
    }
PROXIES_LIST = ["",""]# Add proxies here
##### msgs #####
ERROR = "\033[0;37m[\033[0;31m-\033[0;37m]\033[0;0m"
INFO = "\033[0;37m[\033[0;34mi\033[0;37m]\033[0;0m"
WARNING = "\033[0;37m[\033[0;33m!\033[0;37m]\033[0;0m"
SUCESS = "\033[0;37m[\033[0;32m+\033[0;37m]\033[0;0m"
FATAL_ERROR = "\033[0;37m[\033[41;37mFATAL ERROR\033[0;37m]\033[0;0m"
NMAP = "\033[0;37m[\033[42;30mNMAP\033[0;37m]\033[0;0m"
### colors ###
BLUE = "\033[0;34m"
GREEN = "\033[0;32m"
YELLOW = "\033[0;33m"
RED = "\033[0;31m"
PURPLE = "\033[0;35m"
DEFAULT = "\033[0;0m"

def main():
        # Banner 
        print("""\033[35m
              _____ \033[0m
    ,===,   \033[35m /_    \\_ \033[0m
   //        \033[35m  \\     \\ \033[0m
  || \033[32m/\\\033[35m         |_____\\  \033[37m
  || \033[32m\\/\033[37m        /c ¬ ,¬|)             \033[45;30m WWWizard \033[0;37m
   \\\\          )(\\/¨¨\\'(      \033[37m||\033[37m     Version : beta : 1.1
    ||_\033[35m _______/  \033[37m\\  /\033[35m \\ \033[37m_____||\033[37m
    B|_\033[35m|\033[37m           \\/  \033[37m / --- //\033[37m
    || \033[35m|.-.----.   ::  \033[37m/ --- //\033[37m
    ||         \033[35m|   :: \033[37m/___ooo/\033[37m
    ||         \033[35m\\========/\033[37m
    ||         \033[35m/        |\033[37m
    ||        \033[35m/         |\033[37m
    ||       \033[35m/          |\033[37m
    ||      \033[35m/           |\033[37m
    |'     \033[35m/____________|\033[37m
\033[0m""")
        
        parser = argparse.ArgumentParser(description="Web Security Tool.")
        parser.add_argument("--scan",help="Website to Scan :  http://NNN.NNNNN.NNN/")
        parser.add_argument("--brute",help="Website url to Brute Force : http://NNN.NNNNN.NNN/")
        parser.add_argument("--fuzzing",help="Website to Fuzz :  http://NNN.NNNNN.NNN/")
        parser.add_argument("--sql-inject",help="Website to inject sql :  http://NNN.NNNNN.NNN/")
        parser.add_argument("-d", "--data", help="Data/Payload example \"user=admin&password=password\"")
        parser.add_argument("-v","--verbose",action="store_true",default=False, help="Verbose")
        parser.add_argument("--tor", help="tor / annomity")
        parser.add_argument("-rh", "--rotate-headers",action="store_true",default=False, help="")
        parser.add_argument("-rp", "--rotate-proxies",action="store_true",default=False, help="")
        parser.add_argument("-w", "--wordlist",help="Wordlist")
        parser.add_argument("-ul", "--userlist", help="Userlist")
        parser.add_argument("-p", "--param",help="param")
        parser.add_argument("-th", "--threads",default="1", help="Max Threads")
        parser.add_argument("-tm", "--timeout",default="10", help="Timeout")
        parser.add_argument("-em", "--errormsg", help="Error msg")
        args = parser.parse_args()
        
        login_url = args.brute
        wordlist = args.wordlist
        errormsg = args.errormsg
        maxthreads = int(args.threads)
        timeout = int(args.timeout)
        userlist = args.userlist
        data = args.data
        fuzzing = args.fuzzing
        tor_onion = args.tor
        rotate_headers = args.rotate_headers
        rotate_proxies = args.rotate_proxies
        verbose = args.verbose
        param = args.param
        scan = args.scan
        now = datetime.now()
        
        print(f"{INFO} Starting WWWizard at {now}")

        if data and wordlist and userlist:
                bruteforce_2wordlists(data,login_url,wordlist,errormsg,userlist,maxthreads,timeout,rotate_headers,rotate_proxies,verbose,tor_onion)
                
        elif data and wordlist and not userlist:
                bruteforce_1wordlists(data,login_url,wordlist,errormsg,maxthreads,timeout,rotate_headers,rotate_proxies,verbose,tor_onion)
        elif fuzzing and wordlist:
                fuzz(fuzzing,wordlist,maxthreads,timeout,rotate_headers,rotate_proxies,verbose,tor_onion)
        elif scan:
                scan_general(scan,timeout,param,tor_onion)
        else:
                pass

def connection(url,timeout):
        print(f"{INFO} Connecting to : {url}")
        if not url.startswith("https://") or url.startswith("http://"):
                url = "https://"+url
        try:
                urlpaths = "https://"+url
                rcheck = requests.get(url,timeout=timeout)
                if int(rcheck.status_code) in [200,201,202,203,204,205,206,207,208]:
                        print(f"{SUCESS} {PURPLE}{rcheck.status_code}{DEFAULT} : {url}")
                else:
                        print(f"{WARNING} {PURPLE}{rcheck.status_code}{DEFAULT} : {url}")
                server = rcheck.headers.get("Server")
                print(f"{INFO} Server : {PURPLE}{server}{DEFAULT}")
        except Exception as e:
                print(f"{FATAL_ERROR} Initial connection failed : {url} {e}")
                return

def captcha_detector(url,timeout):
        r = requests.get(url,timeout=timeout)
        text = r.text
        for pattern in CAPTCHA_PATTERNS:
                if pattern.lower() in text.lower():
                        return "Captcha detected !"
                        break
def waf_detector(url,timeout):
        r = requests.get(url,timeout=timeout)
        headers_str = str(r.headers).lower()
        text = r.text.lower()
        for waf_name, patterns in WAF_PATTERNS.items():
                for pattern in patterns:
                        if (re.search(pattern, headers_str, re.IGNORECASE) or re.search(pattern, text, re.IGNORECASE)):
                                return waf_name
        return None

def scan_general(url,timeout,param,tor_onion):
        import socket
        import nmap
        start = time.time()
        connection(url,timeout)
        waf = waf_detector(url,timeout)
        if waf:
                print(f"{WARNING} WAF detected {waf}")
        else:
                pass
        
        if not url.startswith("https://") or url.startswith("http://"):
                urlpaths = "https://"+url
        else:
                urlpaths = url

        testxss = "?q=3211123test"
        
        v_paths = ["/.git","/.env","/phpinfo.php","/wp-admin","/administrator",
                   "/admin.php","/backup.zip","/db.sql","/config.php","/.svn",
                   "/.DS_store","/.gitignore","/.htpasswd","/.htaccess","/index.php",
                   "/admin","/cpanel","/login","/dashboard","/server-info","/phpmyadmin",
                   "/wp-config.php","/etc/shadow","/api","/wp-login.php"]

        security_headers = ["Content-Security-Policy",
                            "X-Frame-Options",
                            "X-XSS-Protection",
                            "Strict-Transport-Security",
                            "X-Content-Type-Options",
                            "Referrer-Policy",
                            "Permissions-Policy",
                            "Cross-Origin-Resource-Policy",
                            "Cross-Origin-Opener-Policy",
                            "Cross-Origin-Opener-Policy"]
        
        sql_errors = ["SQL syntax",
                      "mysql_fecth",
                      "ORA-01756",
                      "Warning: mysql",
                      "Unclosed quotation mark",
                      "ODBC",
                      "PostgreSQL",
                      "You have an error in your SQL"]
        
        domain = url.replace("https://","").replace("http://","").split("/")[0]
        openports = []
        success_urls = []
        w_header = []
        vuln_to_sql = False
        vuln_to_xss = False

        if tor_onion:
                proxies_r = {"http":"socks5h://127.0.0.1:9050",
                           "https":"socks5h://127.0.0.1:9050"}
        else:
                proxies_r = {}

        try:
                ip = socket.gethostbyname(domain)
                print(f"{INFO} Server IP : {ip}")
        except:
                print(f"{WARNING} Could not obtain the ip addres.")
        print(f"+{NMAP} Looking for open ports.")
        nm = nmap.PortScanner()
        nm.scan(ip,"1-10000")
        for host in nm.all_hosts():
                for proto in nm[host].all_protocols():
                        lport = nm[host][proto].keys()
                        for port in lport:
                                print(f"|-[*] Port : {port} State : {nm[host][proto][port]['state']}")
                                openports.append(f"|-[*] Port : {port} State : {nm[host][proto][port]['state']}")
        if not openports:
                print(f"|- No open ports found.")
        else:
                pass
        print(f"+{INFO} searching vulnerable paths...")
        for path in v_paths:
                urlpath = urlpaths+path
                try:
                        r = requests.get(urlpath, timeout=timeout,proxies=proxies_r)
                except requests.exceptions.Timeout as e:
                        print(f"{FATAL_ERROR} Timeout slow server or blocked : {DEFAULT}{url1}")
                except requests.exceptions.ProxyError as e:
                        print(f"{WARNING} Proxy Failed : {DEFAULT}{current_proxies} ")
                except KeyboardInterrupt:
                        print(f"{WARNING} Exiting...")
                except Exception as e:
                        print(f"{ERROR} {e}")
                        
                time.sleep(random.uniform(0.3, 1)) 

                if int(r.status_code) in [200,201,202,203,204,205,206,207,208] and not "not found" in r.text.lower() and not "404" in r.text.lower():
                        print(f"|-[*] {GREEN}{r.status_code}{DEFAULT} : {urlpath}")
                        success_urls.append(f"URL : {urlpath} | Status code : {r.status_code} ")
                elif int(r.status_code) in [300,301,302,303,304,305,306,307,308]:
                        print(f"|-[*] {YELLOW}{r.status_code}{DEFAULT} : {urlpath}")
                else:
                        pass
        urlpath = urlpaths+"robots.txt"
        try:
                r = requests.get(urlpath, timeout=timeout,proxies=proxies_r)
                if int(r.status_code) in [200,201,202,203,204,205,206,207,208]:
                        print(f"|-{INFO} Robots.txt found !")
                        text = r.text
                        ask = input("+- Show the content of robots.txt?(Y/N) ")
                        if ask.lower() in ["y","yes"]:
                                print(text[:500])
                        else:
                                pass
                else:
                        pass
        except requests.exceptions.Timeout as e:
                print(f"{FATAL_ERROR} Timeout slow server or blocked : {DEFAULT}{url1}")
        except requests.exceptions.ProxyError as e:
                print(f"{WARNING} Proxy Failed : {DEFAULT}{current_proxies} ")
        except KeyboardInterrupt:
                print(f"{WARNING} Exiting...")
        except Exception as e:
                print(f"{ERROR} {e}")
                        
        print(f"+{INFO} Looking to see if it has security headers.")
        r = requests.get(urlpaths, timeout=timeout,proxies=proxies_r)
        for h in security_headers:
                if h not in r.headers:
                        print(f"|-{WARNING} Header {h} not found in {urlpaths}.")
                        w_header.append(h)
                else:
                        pass
        print(f"+{INFO} looking if it is vulnerable to sql injection.")

        time.sleep(random.uniform(0.3, 1))
        try:
                r = requests.get(urlpaths,params={param:"'"},timeout=timeout,proxies=proxies_r)
        
                text = r.text
                for sqle in sql_errors :
                        if sqle in r.text:
                                print(f"|-[*] {urlpaths} is vulnerable! msg error : {sqle}")
                                vuln_to_sql = True
                        else:
                                pass
        except requests.exceptions.Timeout as e:
                print(f"{FATAL_ERROR} Timeout slow server or blocked : {DEFAULT}{url1}")
        except requests.exceptions.ProxyError as e:
                print(f"{WARNING} Proxy Failed : {DEFAULT}{current_proxies} ")
        except KeyboardInterrupt:
                print(f"{WARNING} Exiting...")
        except Exception as e:
                print(f"{ERROR} {e}")
                        

        if not vuln_to_sql:
                print(f"+{WARNING} {urlpaths} does not appear to be vulnerable to SQL Injection.")
                
        time.sleep(random.uniform(0.3, 1))
        
        urlpath = urlpaths+testxss
        try:
                r = requests.get(urlpath,timeout=timeout,proxies=proxies_r)
                text = r.text
                print(f"+{INFO} looking if it is vulnerable to XSS.")
                if "3211123test" in text:
                        print(f"|-[*] {urlpath} is vulnerable!")
                        vuln_to_xss = True
                else:
                        pass
        except requests.exceptions.Timeout as e:
                print(f"{FATAL_ERROR} Timeout slow server or blocked : {DEFAULT}{url1}")
        except requests.exceptions.ProxyError as e:
                print(f"{WARNING} Proxy Failed : {DEFAULT}{current_proxies} ")
        except KeyboardInterrupt:
                print(f"{WARNING} Exiting...")
        except Exception as e:
                print(f"{ERROR} {e}")
                        
        if not vuln_to_xss:
                print(f"+{WARNING} {urlpaths} does not appear to be vulnerable to XSS.")
        end = time.time()
        print(f"+{INFO} Web Scanned in {end - start} seconds.")
        ask = input(f"{DEFAULT}+-[*] Do you want to save the results to a file (Y/N)? ")
        if ask.lower() in ["y","yes"] :
                file = input(f"{DEFAULT}+-[*] File name (filename.txt) : ")
                with open(file,"w",encoding="utf-8") as filew:
                        filew.write(f"""
+---------------[ Scan Report ]----------------
|----------------------------------------------
| WWWizard Web security tool
| {datetime.now()}
|
+----------------[ URL founds ]----------------\n""")
                        for a in success_urls:
                                filew.write("|-"+a+"\n")
                        filew.write("+----------------[ Open ports ]----------------\n")
                        for p in openports:
                                filew.write(p+"\n")
                        filew.write("+------------------[ Headers ]-----------------\n")
                        for hh in w_header:
                                filew.write("|- Header not found : "+hh+"\n")
                        filew.write(f"""+--------------[ SQL Injection ]---------------
| Vulnerable : {vuln_to_sql}
+-------------------[ XSS ]--------------------
| vulnerable : {vuln_to_xss}
+----------------------------------------------
""")
                print(f"{SUCESS} Results saved in {file}.")
        else:
                pass

def fuzz(fuzzing, wordlist, maxthreads, timeout,rotate_headers,rotate_proxies,verbose,tor_onion):
        success_urls = []
        
        if not fuzzing.startswith("https://") or fuzzing.startswith("http://"):
                url = "https://"+fuzzing
        else:
                url = fuzzing

        connection(url,timeout)
        
        detect_captcha = captcha_detector(url,timeout)
        if detect_captcha:
                print(f"{WARNING} {detect_captcha}{DEFAULT}")
        else :
                pass

        detect_waf = waf_detector(url,timeout)
        
        if detect_waf:
                print(f"{WARNING} WAF Detected : {detect_waf}")
        else :
                pass
        
        print(f"{INFO} Threads : {maxthreads}")
        
        def fuzz1(lines):

                lines

                url1 = url + lines.strip()

                time.sleep(random.uniform(0.3, 1))
                if rotate_headers:
                        current_headers = random.choice(USER_AGENTS) if USER_AGENTS else {}
                else:
                        current_headers = DEFAULT_HEADERS
                if rotate_proxies:
                        current_proxies = random.choice(PROXIES_LIST) if PROXIES_LIST else None
                elif tor_onion:
                        current_proxies = "socks5h://127.0.0.1:9050"
                else:
                        current_proxies = ""

                if isinstance(current_proxies, str):
                        current_proxies = {
        "http": current_proxies,
        "https": current_proxies
                        }
                elif not isinstance(current_proxies, dict):
                        current_proxies = None
                try:
                        r = requests.get(url1, headers=current_headers,proxies=current_proxies, timeout=timeout)
                        response_text = r.text

                except requests.exceptions.Timeout as e:
                        print(f"{FATAL_ERROR} Timeout slow server or blocked : {DEFAULT}{url1}")
                except requests.exceptions.ProxyError as e:
                        print(f"{WARNING} Proxy Failed : {DEFAULT}{current_proxies} ")
                except KeyboardInterrupt:
                        print(f"{WARNING} Exiting...")
                except Exception as e:
                        print(f"{ERROR} {e}")
                        
                if int(r.status_code) in [200,201,202,203,204,205,206,207,208] and not "not found" in response_text.lower() and not "404" in response_text.lower():
                        print(f"[*] {GREEN}{r.status_code}{DEFAULT} : {url1}")
                        success_urls.append(f"URL : {url1} | Status code : {r.status_code} ")
                elif int(r.status_code) in [300,301,302,303,304,305,306,307,308]:
                        print(f"[*] {YELLOW}{r.status_code}{DEFAULT} : {url1}")
                elif int(r.status_code) in range(400,599) and verbose:
                        print(f"[*] {RED}{r.status_code}{DEFAULT} : {url1}")
                else:
                        pass
        try:
                with open(wordlist, encoding="utf-8") as wrdlist:
                        lines = [l.strip() for l in wrdlist if l.strip()]
        except Exception as e:
                print(f"{ERROR} Error when trying to open the file : {wordlist} \n {e}")
                return
        
        print(f"{INFO} Casting fuzzing spell...")
        start = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=maxthreads) as executor:
                executor.map(fuzz1, lines)

        if success_urls != []:
                print(f"{DEFAULT}------------[{GREEN} Results {DEFAULT}]------------")
                for g in success_urls:
                        print(f"{SUCESS} {g}")
                end = time.time()
                print(f"{INFO} Paths scanned in {end - start} seconds.")
                print(f"{INFO} Total urls found :{DEFAULT} {len(success_urls)}")
                ask = input(f"{DEFAULT}[*] Do you want to save the results to a file (Y/N)? ")
                if ask.lower() in ["y","yes"] :
                        file = input(f"{DEFAULT}[*] File name (filename.txt) : ")
                        with open(file,"w",encoding="utf-8") as filew:
                                for a in success_urls:
                                        filew.write(a+"\n")
                        print(f"{SUCESS} Results saved in {file}.")
                else:
                        pass
        else:
                print(f"{WARNING} Not Path found in {fuzzing} using {wordlist}.")
                return

def connect1(params):
        usr,psswrd,stop_event,data,login_url,errormsg,timeout,rotate_headers,rotate_proxies,verbose,start,tor_onion = params
        if stop_event.is_set():
                return None
        payload = data.replace("$usr", usr).replace("$psswrd", psswrd)
        if "=" in payload and "&" in payload:
                from urllib.parse import parse_qs
                parsed = parse_qs(payload)
                payload = {k: v[0] if len(v) == 1 else v for k, v in parsed.items()}

        else:
                print(f"{WARNING} Data written incorrectly !")
                print(f"{DEFAULT}[*] example :{DEFAULT} \"user=admin&password=$psswrd&form=login\" ")
                print(f"{DEFAULT}[*] {DEFAULT}Write python wwwizard.py --help for more help.")
                return
        if rotate_headers:
                headers_choice = random.choice(USER_AGENTS)
        else:
                headers_choice = DEFAULT_HEADERS

        if rotate_proxies:
                current_proxies = random.choice(PROXIES_LIST)
        elif tor_onion:
                current_proxies = "socks5h://127.0.0.1:9050"
        else:
                current_proxies = ""
                
        time.sleep(random.uniform(0.3, 1))

        if isinstance(headers_choice, dict):
                current_headers = headers_choice
        elif isinstance(headers_choice, str):
                current_headers = {"User-Agent": headers_choice}
        else:
                pass
        if isinstance(current_proxies, str):
                current_proxies = {
                "http" : current_proxies,
                "https": current_proxies
                                }
        elif not isinstance(current_proxies, dict):
                current_proxies = None

        try:
                session = requests.Session()

                response = session.post(login_url, data=payload,headers=current_headers,proxies=current_proxies,timeout=timeout)

        except requests.exceptions.Timeout as e:
                print(f"{FATAL_ERROR} Timeout, slow server or blocked : {login_url}")
                return
        except requests.exceptions.ProxyError as e:
                print(f"{WARNING} Proxy Failed : {current_proxies} ")
                pass
        except KeyboardInterrupt:
                print(f"{WARNING} Exiting...")
                stop_event.set()
        except Exception as e:
                print(f"{ERROR} {e}")
                return

        if errormsg and not errormsg.lower() in response.text.lower():
                end = time.time()
                print(f"{DEFAULT}+------------[{GREEN} Login found!{DEFAULT} ]------------")
                print(f"{DEFAULT}| {SUCESS} User found! : {usr}")
                print(f"{DEFAULT}| {SUCESS} Password found! : {psswrd}")
                print(f"{DEFAULT}| {SUCESS} Login form : {payload}")
                print(f"{DEFAULT}| {INFO} Credentials found in {end - start} seconds.")
                print(f"{DEFAULT}+----------------------------------------")
                stop_event.set()
                return(usr,psswrd)
        elif errormsg and errormsg.lower() in response.text.lower() and verbose:
                print(f"{DEFAULT}+---------------[{BLUE} Attempt {DEFAULT}]---------------+")
                print(f"{DEFAULT}|[*] Attempt : {DEFAULT}{usr} | {psswrd}")
                print(f"{DEFAULT}|[*] Server response : {response.status_code}")
                print(f"{DEFAULT}|[*] Data : {DEFAULT}{payload}")
                print(f"{DEFAULT}+-----------------------------------------+")
                return False
        else:
                return False

def bruteforce_2wordlists(data,login_url,wordlist,errormsg,userlist,maxthreads,timeout,rotate_headers,rotate_proxies,verbose,tor_onion):

        connection(login_url,timeout)
        
        print(f"{INFO} Trying to open the files : {wordlist} , {userlist}")
        try:
                with open(userlist,encoding="utf-8") as usrlist:
                        usr = [ll.strip() for ll in usrlist if ll.strip()]
        except Exception as e:
                print(f"{ERROR} Error when trying to open the file : {wordlist} \n {e}")
        try:        
                with open(wordlist,encoding="utf-8") as wrdlist:
                        psswrd = [l.strip() for l in wrdlist if l.strip()]
                
        except Exception as e:
                print(f"{ERROR} Error when trying to open the file : {userlist} \n {e}")

        detect_captcha = captcha_detector(login_url,timeout)
        if detect_captcha:
                print(f"{WARNING} {detect_captcha}")
        else :
                pass

        detect_waf = waf_detector(login_url,timeout)
        
        if detect_waf:
                print(f"{WARNING} WAF Detected : {detect_waf}")
        else :
                pass
        
        print(f"{INFO} Casting brute force spell...")
        start = time.time()
        with multiprocessing.Manager() as manager:
                stop_event = manager.Event()
                combinations = [(u, p,stop_event,data,login_url,errormsg,timeout,rotate_headers,rotate_proxies,verbose,start,tor_onion) for u in usr for p in psswrd]
                with multiprocessing.Pool(processes=maxthreads) as pool:
                        try:
                                for result in  pool.imap_unordered(connect1,combinations,chunksize=10):
                                        if result and result is not False:
                                                pool.terminate()
                                                pool.join()
                                                return result
                        except Exception as e:
                                print(f"{FATAL_ERROR} Multiprocessing error : {e}")
        return None

def connect(psswrd,data,login_url,errormsg,stop_event,rotate_headers,rotate_proxies,verbose,start,tor_onion):
        if stop_event.is_set():
                return None
        if isinstance(data, str):
                if "=" in data and ("&" in data or "$psswrd" in data):
                        from urllib.parse import parse_qs
                        data_clean = data.replace("$psswrd", psswrd)
                        parsed = parse_qs(data_clean)
                        payload = {k: v[0] if len(v) == 1 else v for k, v in parsed.items()}
                else:
                        payload = data
                        pass
        else:
                print(f"{WARNING} Data written incorrectly !")
                print(f"{DEFAULT}[*] example : \"user=admin&password=$psswrd&form=login\" ")
                print(f"{DEFAULT}[*] Write python wwwizard.py --help for more help.\033[0m")
                return
        if rotate_headers:        
                headers_choice = random.choice(USER_AGENTS)
        else:
                headers_choice = DEFAULT_HEADERS
        if rotate_proxies:
                current_proxies = random.choice(PROXIES_LIST)
        if tor_onion:
                current_proxies = "socks5h://127.0.0.1:9050"
        else:
                current_proxies = "" # you can set a default proxie

        time.sleep(random.uniform(0.3, 1))

        if isinstance(headers_choice, dict):
                current_headers = headers_choice
        elif isinstance(headers_choice, str):
                current_headers = {"User-Agent": headers_choice}
        else:
                pass
        if isinstance(current_proxies, str):
                current_proxies = {
        "http": current_proxies,
        "https": current_proxies
                        }
        elif not isinstance(current_proxies, dict):
                current_proxies = None
        response = ""
        
        try :
                session = requests.Session()
                response = session.post(login_url, data=payload,headers=current_headers)
                text = response.text
        except requests.exceptions.Timeout as e:
                print(f"{FATAL_ERROR} Timeout, slow server or blocked : {login_url}")
                return
        except requests.exceptions.ProxyError as e:
                print(f"{WARNING} Proxy Failed : {current_proxies} ")
                pass
        
        except KeyboardInterrupt:
                print(f"{WARNING} Exiting...")
                stop_event.set()
                
        except Exception as e:
                print(f"{ERROR} {e}")
                return
        if errormsg and not errormsg.lower() in text.lower():
                end = time.time()
                print(f"{DEFAULT}+------------[{GREEN} Login found! {DEFAULT}]------------+")
                print(f"{DEFAULT}| {SUCESS} Password found! : {psswrd}")
                print(f"{DEFAULT}| {SUCESS} Login form : {payload}")
                print(f"{DEFAULT}| {INFO} Credentials found in {end - start} seconds.")
                print(f"{DEFAULT}+----------------------------------------+")
                stop_event.set()
                return psswrd
        elif errormsg and errormsg.lower() in response.text.lower() and verbose:
                print(f"{DEFAULT}+---------------[{BLUE} Attempt {DEFAULT}]---------------+")
                print(f"{DEFAULT}|[*] Attempt : {DEFAULT} {psswrd}")
                print(f"{DEFAULT}|[*] Server response : {response.status_code}")
                print(f"{DEFAULT}|[*] Data : {DEFAULT}{payload}")
                print(f"{DEFAULT}+-----------------------------------------+")
                return False
        else:
                return False

                
def bruteforce_1wordlists(data,login_url,wordlist,errormsg,maxthreads,timeout,rotate_headers,rotate_proxies,verbose,tor_onion):
        connection(login_url,timeout)
        detect_captcha = captcha_detector(login_url,timeout)
        if detect_captcha:
                print(f"{WARNING} {detect_captcha}")
        else :
                pass

        detect_waf = waf_detector(login_url,timeout)
        
        if detect_waf:
                print(f"{WARNING} WAF Detected : {detect_waf}")
        else :
                pass
        
        print(f"{INFO} Threads : {maxthreads}")
        print(f"{INFO} Trying to open the file : {wordlist}")

        try :
                with open(wordlist,encoding="utf-8") as wrdlist:
                        psswrd = [l.strip() for l in wrdlist if l.strip()]
        except Exception as e:
                print(f"{ERROR} Error when trying to open the file : {wordlist} \n {e}")
                return None
        print(f"{INFO} Casting brute force spell...")
        start = time.time()
        with multiprocessing.Manager() as manager:
                stop_event = manager.Event()
                worker = partial(connect, 
                    data=data, 
                    login_url=login_url, 
                    errormsg=errormsg, 
                    stop_event=stop_event,
                    rotate_headers=rotate_headers,
                    rotate_proxies=rotate_proxies,
                    verbose=verbose,
                    start=start,
                    tor_onion=tor_onion)
                with multiprocessing.Pool(processes=maxthreads) as pool:
                        for result in pool.imap_unordered(worker, psswrd):
                                if result and result is not True:
                                        pool.terminate()
                                        pool.join()
                                        return result
        return None

if __name__ == "__main__":
    main()


